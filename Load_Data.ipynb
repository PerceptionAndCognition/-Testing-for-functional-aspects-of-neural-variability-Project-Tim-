{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does PICKLING work? \n",
    "#TAKES OBJECT (DICTIONARY; LIST) AND SAVES IT AS A PICKLE FILE AND LATER IT CAN BE UNPICKELD \n",
    "import pickle \n",
    "with open ('data_first_five.pkl', 'wb') as pickle_file:   #Save data to it\n",
    "    pickle.dump(conc_epoch, pickle_file)                  #Write Data to new file \n",
    "#'wb'= write binary\n",
    "#with open and closes the file\n",
    "#File name: 'C:/User path to the data'\n",
    "\n",
    "###Read Data from the file- Depickle\n",
    "with open ('data_first_five.pkl', 'rb') as pickle_file:\n",
    "    new_data_first_five = pickle.load(pickle_file)\n",
    "#rb = read binary\n",
    "\n",
    "#print (conc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "######################## CONCATENATE LIST##################################\n",
    "###########################################################################\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import median_absolute_deviation as mad\n",
    "from scipy.stats import pearsonr\n",
    "from mne.io.proj import _proj_equal\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "from Definitions import *\n",
    "%matplotlib qt\n",
    "\n",
    "List_of_files = list_files('C:/User path to the data')\n",
    "print ('Len of the files', len(List_of_files))\n",
    "\n",
    "#List of people: \n",
    "List_of_People = os.listdir('C:/User path to the data')\n",
    "\n",
    "#All the Epochs from the Files in the list above\n",
    "List_Conc_per_person = []\n",
    "count = 0\n",
    "#Loop to extract all the Epochs:\n",
    "for i in range (len (List_of_files)):\n",
    "    count +=1 \n",
    "    print (count)\n",
    "    filename = List_of_files[i]\n",
    "    Preprocessed_data = preprocessing (filename)\n",
    "    epochs = Get_Epochs (Preprocessed_data)\n",
    "    List_Conc_per_person.append(epochs)\n",
    "    [print('BAD EPOCHS: ',List_Conc_per_person[i].info['bads']) for i in range(len(Epochs_loop))]\n",
    "\n",
    "    # if count == 42:\n",
    "    #     break\n",
    "\n",
    "conc_epoch = concatenate_epochs (Epochs_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of memory errors I divided the 18 data sets into pairs of 6 and pickled them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "################################################## LOAD DATA [0:6] ############################################################\n",
    "###############################################################################################################################\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import median_absolute_deviation as mad\n",
    "from scipy.stats import pearsonr\n",
    "from mne.io.proj import _proj_equal\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "from Definitions import *\n",
    "import gc #To save memory- not sure what it does ^^ but it worked\n",
    "#import resource #To save memory- not sure what it does ^^ but it worked\n",
    "gc.collect() #To save memory- not sure what it does ^^ but it worked\n",
    "\n",
    "#List of People for the Loop:\n",
    "List_of_People_incomplete = []\n",
    "List_to_loop = os.listdir('C:/User path to the data')\n",
    "for ii in range (len(List_to_loop)):\n",
    "    if not '_' in List_to_loop[ii]:\n",
    "        List_of_People_incomplete.append(List_to_loop[ii])\n",
    "print (List_of_People_incomplete)\n",
    "List_of_People = List_of_People_incomplete[0:6]\n",
    "print (List_of_People)\n",
    "\n",
    "#Loop through files and get the Data:\n",
    "List_of_files = list_files('C:/User path to the data')\n",
    "#Empty list for the concatented epochs per person\n",
    "List_Conc_per_person_first = []\n",
    "\n",
    "#Count- can be removed when analysing the whole data set \n",
    "# count = 0 \n",
    "logging.basicConfig(filename='data_process.log',level=logging.DEBUG)\n",
    "\n",
    "for aa in range (len(List_of_People)):\n",
    "    #Count- can be removed when analysing the whole data set\n",
    "    # count +=1 \n",
    "    # if count == 6:\n",
    "    #     break\n",
    "    Epochs_loop = []\n",
    "    subnumber = aa\n",
    "    logging.info(f'Performing ica- Process subject {aa}')\n",
    "    for bb in range (len(List_of_files)):\n",
    "        if List_of_People[aa] in List_of_files[bb]:\n",
    "            #Get the file name \n",
    "            filename = List_of_files[bb]\n",
    "            #Preprocessing- Make raw data, filter the data, detect bad channels, ICA\n",
    "            Preprocessed_data = preprocessing (filename)\n",
    "            #Get Epochs- get annotations, get events from annotations, get epochs\n",
    "            epochs = Get_Epochs (Preprocessed_data)\n",
    "            #Append to List\n",
    "            Epochs_loop.append(epochs)\n",
    "            #print bad channel information if Bad epochs\n",
    "            #[print('BAD EPOCHS: ',List_Conc_per_person[i].info['bads']) for i in range(len(Epochs_loop))]\n",
    "\n",
    "    #Concatenate epochs per person and append it to a new list\n",
    "    conc_epoch = concatenate_epochs (Epochs_loop)\n",
    "    List_Conc_per_person_first.append(conc_epoch)\n",
    "\n",
    "del (conc_epoch, Epochs_loop, filename, Preprocessed_data, epochs, List_of_People)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I pickeled the data \n",
    "import pickle \n",
    "with open ('List_Conc_per_person_first.pkl', 'wb') as pickle_file:                    #Save data to it\n",
    "    pickle.dump(List_Conc_per_person_first, pickle_file)                                          #Write Data to new file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "################################################## LOAD DATA [6:12] ############################################################\n",
    "###############################################################################################################################\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import median_absolute_deviation as mad\n",
    "from scipy.stats import pearsonr\n",
    "from mne.io.proj import _proj_equal\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "from Definitions import *\n",
    "import gc \n",
    "#import resource \n",
    "gc.collect() \n",
    "\n",
    "#List of People for the Loop:\n",
    "List_of_People_incomplete = []\n",
    "List_to_loop = os.listdir('C:/User path to the data')\n",
    "for ii in range (len(List_to_loop)):\n",
    "    if not '_' in List_to_loop[ii]:\n",
    "        List_of_People_incomplete.append(List_to_loop[ii])\n",
    "print (List_of_People_incomplete)\n",
    "List_of_People = List_of_People_incomplete[0:6]\n",
    "print (List_of_People)\n",
    "\n",
    "#Loop through files and get the Data:\n",
    "List_of_files = list_files('C:/User path to the data')\n",
    "\n",
    "List_of_People_second = List_of_People_incomplete[6:12]\n",
    "List_Conc_per_person_second = []\n",
    "\n",
    "for aa in range (len(List_of_People_second)):\n",
    "    #Count- can be removed when analysing the whole data set\n",
    "    # count +=1 \n",
    "    # if count == 6:\n",
    "    #     break\n",
    "    Epochs_loop = []\n",
    "\n",
    "    for bb in range (len(List_of_files)):\n",
    "        if List_of_People_second[aa] in List_of_files[bb]:\n",
    "            #Get the file name \n",
    "            filename = List_of_files[bb]\n",
    "            #Preprocessing- Make raw data, filter the data, detect bad channels, ICA\n",
    "            Preprocessed_data = preprocessing (filename)\n",
    "            #Get Epochs- get annotations, get events from annotations, get epochs\n",
    "            epochs = Get_Epochs (Preprocessed_data)\n",
    "            #Append to List\n",
    "            Epochs_loop.append(epochs)\n",
    "            #print bad channel information if Bad epochs\n",
    "            #[print('BAD EPOCHS: ',List_Conc_per_person[i].info['bads']) for i in range(len(Epochs_loop))]\n",
    "\n",
    "    #Concatenate epochs per person and append it to a new list\n",
    "    conc_epoch = concatenate_epochs (Epochs_loop)\n",
    "    List_Conc_per_person_second.append(conc_epoch)\n",
    "\n",
    "del (conc_epoch, Epochs_loop, filename, Preprocessed_data, epochs, List_of_People_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I pickeled the data \n",
    "import pickle \n",
    "with open ('List_Conc_per_person_second.pkl', 'wb') as pickle_file:                    #Save data to it\n",
    "    pickle.dump(List_Conc_per_person_second, pickle_file)                                          #Write Data to new file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "################################################# LOAD DATA [12:18] ###########################################################\n",
    "###############################################################################################################################\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import median_absolute_deviation as mad\n",
    "from scipy.stats import pearsonr\n",
    "from mne.io.proj import _proj_equal\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "from Definitions import *\n",
    "import gc \n",
    "#import resource \n",
    "gc.collect() \n",
    "\n",
    "#List of People for the Loop:\n",
    "List_of_People_incomplete = []\n",
    "List_to_loop = os.listdir('C:/User path to the data')\n",
    "for ii in range (len(List_to_loop)):\n",
    "    if not '_' in List_to_loop[ii]:\n",
    "        List_of_People_incomplete.append(List_to_loop[ii])\n",
    "print (List_of_People_incomplete)\n",
    "List_of_People = List_of_People_incomplete[0:6]\n",
    "print (List_of_People)\n",
    "\n",
    "#Loop through files and get the Data:\n",
    "List_of_files = list_files('C:/User path to the data')\n",
    "\n",
    "List_of_People_third = List_of_People_incomplete[12:18]\n",
    "List_Conc_per_person_third = []\n",
    "\n",
    "for aa in range (len(List_of_People_third)):\n",
    "    #Count- can be removed when analysing the whole data set\n",
    "    # count +=1 \n",
    "    # if count == 6:\n",
    "    #     break\n",
    "    Epochs_loop = []\n",
    "\n",
    "    for bb in range (len(List_of_files)):\n",
    "        if List_of_People_third[aa] in List_of_files[bb]:\n",
    "            #Get the file name \n",
    "            filename = List_of_files[bb]\n",
    "            #Preprocessing- Make raw data, filter the data, detect bad channels, ICA\n",
    "            Preprocessed_data = preprocessing (filename)\n",
    "            #Get Epochs- get annotations, get events from annotations, get epochs\n",
    "            epochs = Get_Epochs (Preprocessed_data)\n",
    "            #Append to List\n",
    "            Epochs_loop.append(epochs)\n",
    "            #print bad channel information if Bad epochs\n",
    "            #[print('BAD EPOCHS: ',List_Conc_per_person[i].info['bads']) for i in range(len(Epochs_loop))]\n",
    "\n",
    "    #Concatenate epochs per person and append it to a new list\n",
    "    conc_epoch = concatenate_epochs (Epochs_loop)\n",
    "    List_Conc_per_person_third.append(conc_epoch)\n",
    "\n",
    "del (conc_epoch, Epochs_loop, filename, Preprocessed_data, epochs, List_of_People_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I pickeled the data \n",
    "import pickle \n",
    "with open ('List_Conc_per_person_third.pkl', 'wb') as pickle_file:                    #Save data to it\n",
    "    pickle.dump(List_Conc_per_person_third, pickle_file)                                          #Write Data to new file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOAD DATA AGAIN to make a big list to pickle it again \n",
    "import pickle \n",
    "\n",
    "with open ('List_Conc_per_person_first_ONLY_FILTER.pkl', 'rb') as pickle_file:\n",
    "    List_Conc_per_person_first = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOAD DATA AGAIN to make a big list to pickle it again \n",
    "import pickle \n",
    "\n",
    "with open ('List_Conc_per_person_second_ONLY_FILTER.pkl', 'rb') as pickle_file:\n",
    "    List_Conc_per_person_second = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOAD DATA AGAIN to make a big list to pickle it again \n",
    "with open ('List_Conc_per_person_third_ONLY_FILTER.pkl', 'rb') as pickle_file:\n",
    "    List_Conc_per_person_third = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Conc_per_person = List_Conc_per_person_first + List_Conc_per_person_second + List_Conc_per_person_third\n",
    "del (List_Conc_per_person_first, List_Conc_per_person_second, List_Conc_per_person_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('List_Conc_per_person_ONLY_FILTER.pkl', 'wb') as pickle_file:                    #Save data to it\n",
    "    pickle.dump(List_Conc_per_person_ONLY_FILTER, pickle_file)                  #Write Data to new file "
   ]
  }
 ]
}